{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_tOTNpLokx2",
        "outputId": "42799b30-eaf5-47a2-e515-ac9a6b3f02bc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.46.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.26.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "metadata": {
        "id": "fp6czQ0KorUr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('train_en.txt', sep='\\t')"
      ],
      "metadata": {
        "id": "zQmCK-TZosXF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 't5-base'"
      ],
      "metadata": {
        "id": "6R_sDFNTo2sL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = data['Sentence'].values.tolist()\n",
        "labels = data['Label'].values.tolist()\n",
        "labels = ['toxic' if label==1 else 'non-toxic' for label in labels]"
      ],
      "metadata": {
        "id": "fG-8RLTLozXc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[:3], labels[-3:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w6RtI6no0kB",
        "outputId": "c44e51e2-400b-4aea-d1cd-bab9c4c4d215"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['toxic', 'toxic', 'toxic'], ['non-toxic', 'non-toxic', 'non-toxic'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задача 1: zero-shot"
      ],
      "metadata": {
        "id": "i8MpxroIwX-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_classifier = pipeline(\"zero-shot-classification\", model=model_name, device='cuda', max_length=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFo0FlT4sdMs",
        "outputId": "6df3f859-ea41-4ce0-f1d5-278f17524747"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at t5-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "options = ['toxic', 'non-toxic']"
      ],
      "metadata": {
        "id": "kAhRyskrsfbE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "xQNAbxkztb3q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_pairs = list(zip(sentences, labels))\n",
        "random.shuffle(data_pairs)"
      ],
      "metadata": {
        "id": "bsFOCiLqvU5r"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence, label in data_pairs[:3]:\n",
        "  print(sentence)\n",
        "  result = zero_shot_classifier(sentence, options)\n",
        "  classification_index = result['scores'].index(max(result['scores']))\n",
        "  classification = result['labels'][classification_index]\n",
        "  print(f'Classifcation: {classification}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA_AitQtsy-V",
        "outputId": "ab82f644-8aa8-4dfb-d8d5-d1b8a55e1f15"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You know what part, almost everything you said was made up, now stop talking to me. Douche\n",
            "Classifcation: non-toxic\n",
            "The greater good, kinda the best bet these days\n",
            "Classifcation: non-toxic\n",
            "Useless Congress getting nothing done again.\n",
            "Classifcation: non-toxic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "77cT7XhRvm2N"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []"
      ],
      "metadata": {
        "id": "r7ljLJeCvyq4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Класификација само на тренинг множество бидејќи секако немаме тренирање на модел"
      ],
      "metadata": {
        "id": "arnSFk3DwSnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_random = [pair[0] for pair in data_pairs]\n",
        "labels_random = [pair[1] for pair in data_pairs]"
      ],
      "metadata": {
        "id": "OwQXcgZdzUYS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = zero_shot_classifier(sentences_random, candidate_labels=options)"
      ],
      "metadata": {
        "id": "VOKDtqE_zT1e"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []"
      ],
      "metadata": {
        "id": "qp6iBZGN0gCW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for result in results:\n",
        "  classification_index = result['scores'].index(max(result['scores']))\n",
        "  classification = result['labels'][classification_index]\n",
        "  predictions.append(classification)"
      ],
      "metadata": {
        "id": "5kl31lXgvtnR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Zero-shot accuracy: {accuracy_score(labels_random, predictions)}')\n",
        "print(f'Zero-shot precision: {precision_score(labels_random, predictions, average=\"binary\", pos_label=\"toxic\")}')\n",
        "print(f'Zero-shot recall: {recall_score(labels_random, predictions, average=\"binary\", pos_label=\"toxic\")}')\n",
        "print(f'Zero-shot f1: {f1_score(labels_random, predictions, average=\"binary\", pos_label=\"toxic\")}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL1Tow4Av37j",
        "outputId": "4c54a6ae-e284-4ca3-d67b-bf3450e2ac52"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-shot accuracy: 0.4864267676767677\n",
            "Zero-shot precision: 0.4902846814279259\n",
            "Zero-shot recall: 0.6849747474747475\n",
            "Zero-shot f1: 0.5715038188043192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задача 2 - Few-shot"
      ],
      "metadata": {
        "id": "7p9pscY_2If8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_classifier = pipeline(\"zero-shot-classification\", model=\"t5-base\", device='cuda', max_length=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5XRO3s2q8mJ",
        "outputId": "6dcc2747-ebf7-4d35-cb03-7631579967e4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at t5-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "options = [\"toxic\", \"non-toxic\"]"
      ],
      "metadata": {
        "id": "bL2KIb6T22sG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_few_shot_prompt(num_examples, options, sentences, labels):\n",
        "    prompt = \"\"\n",
        "    for i in range(num_examples):\n",
        "        prompt += f\"Example {i+1}: Sentence: {sentences[i]} Label: {labels[i]}\\n\"\n",
        "\n",
        "    prompt += \"\\nClassify the following sentence into toxic or non-toxic:\\n\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "Fq8YnyEL29CH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def few_shot_classification(sentences, num_examples):\n",
        "    results = []\n",
        "    for i in range(0, len(sentences), 8):\n",
        "        batch_sentences = sentences[i:i + 8]\n",
        "        prompts = [create_few_shot_prompt(num_examples, options, sentences, labels) + f\"Sentence to classify: {sentence}\" for sentence in batch_sentences]\n",
        "\n",
        "        batch_results = zero_shot_classifier(prompts, candidate_labels=options, max_length=20)\n",
        "\n",
        "        for result in batch_results:\n",
        "            classification_index = result['scores'].index(max(result['scores']))\n",
        "            classification = result['labels'][classification_index]\n",
        "            results.append(classification)\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "QSCe51PI3Cvt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_metrics(labels_true, labels_pred):\n",
        "    print(f\"Accuracy: {accuracy_score(labels_true, labels_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(labels_true, labels_pred, pos_label='toxic', average='binary'):.4f}\")\n",
        "    print(f\"Recall: {recall_score(labels_true, labels_pred, pos_label='toxic', average='binary'):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(labels_true, labels_pred, pos_label='toxic', average='binary'):.4f}\")"
      ],
      "metadata": {
        "id": "QQq8tTTB3P7f"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for num_examples in [1, 2, 5, 10]:\n",
        "    print(f\"Few-shot classification with {num_examples} examples:\")\n",
        "    predictions = few_shot_classification(sentences, num_examples)\n",
        "\n",
        "    print(f\"\\nMetrics for {num_examples} examples:\")\n",
        "    print_metrics(labels, predictions)\n",
        "    print(\"\\n\" + \"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2XLxLnZ3Eyu",
        "outputId": "a83deada-2885-4ce0-d3ee-84a11a53244d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few-shot classification with 1 examples:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metrics for 1 examples:\n",
            "Accuracy: 0.5069\n",
            "Precision: 0.6019\n",
            "Recall: 0.0410\n",
            "F1 Score: 0.0768\n",
            "\n",
            "--------------------------------------------------\n",
            "Few-shot classification with 2 examples:\n",
            "\n",
            "Metrics for 2 examples:\n",
            "Accuracy: 0.5666\n",
            "Precision: 0.6435\n",
            "Recall: 0.2986\n",
            "F1 Score: 0.4079\n",
            "\n",
            "--------------------------------------------------\n",
            "Few-shot classification with 5 examples:\n",
            "\n",
            "Metrics for 5 examples:\n",
            "Accuracy: 0.5000\n",
            "Precision: 0.5000\n",
            "Recall: 1.0000\n",
            "F1 Score: 0.6667\n",
            "\n",
            "--------------------------------------------------\n",
            "Few-shot classification with 10 examples:\n",
            "\n",
            "Metrics for 10 examples:\n",
            "Accuracy: 0.5000\n",
            "Precision: 0.5000\n",
            "Recall: 1.0000\n",
            "F1 Score: 0.6667\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ciLoCKFA3TqR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}